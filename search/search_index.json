{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Geo-Epic A toolkit for geospatial crop simulations using EPIC model Overview This package expands the capabilities of the EPIC crop simulation model , to simulate crop growth and development across large geographies, such as entire states or counties by leveraging openly availabe remote sensing products and geospatial databases. Additionally, the toolkit features a unique calibration module that allows fine-tuning of model parameters to reflect specific local conditions or experimental results. This toolkit allows researchers to assess crop production potential, management scenarios and risks at broader scales, informing decision-making for sustainable agricultural practices. Installation Setup a Virtual environment. (conda Recommended) conda create --name epic_env python=3.9 conda activate epic_env Install the EPIC Python Package pip install git+https://github.com/smarsGroup/EPIC-pkg.git Before starting the setup, ensure you have wget and conda installed. Follow the links for corresponding installation guides.","title":"Intro"},{"location":"#geo-epic","text":"A toolkit for geospatial crop simulations using EPIC model","title":"Geo-Epic"},{"location":"#overview","text":"This package expands the capabilities of the EPIC crop simulation model , to simulate crop growth and development across large geographies, such as entire states or counties by leveraging openly availabe remote sensing products and geospatial databases. Additionally, the toolkit features a unique calibration module that allows fine-tuning of model parameters to reflect specific local conditions or experimental results. This toolkit allows researchers to assess crop production potential, management scenarios and risks at broader scales, informing decision-making for sustainable agricultural practices.","title":"Overview"},{"location":"#installation","text":"Setup a Virtual environment. (conda Recommended) conda create --name epic_env python=3.9 conda activate epic_env Install the EPIC Python Package pip install git+https://github.com/smarsGroup/EPIC-pkg.git Before starting the setup, ensure you have wget and conda installed. Follow the links for corresponding installation guides.","title":"Installation"},{"location":"OPC/","text":"Agricultural Management OPC input files refers to the agricultural management practice files. Creating these files is not yet implemented in the toolkit. Refer to the epic user manual on how to prepare the management files.","title":"Crop Management"},{"location":"OPC/#agricultural-management","text":"OPC input files refers to the agricultural management practice files. Creating these files is not yet implemented in the toolkit. Refer to the epic user manual on how to prepare the management files.","title":"Agricultural Management"},{"location":"Soil/","text":"Soil Module In agriculture simulations, such as those conducted using the EPIC model, soil data directly influences water availability, nutrient supply, and overall crop growth predictions. Soil input files to the model contain detailed information about the soil properties of a specific location, depth wise. Geo-Epic helps in generating soil files required by the EPIC Model from two soil data sources: USDA SSURGO : which contains detailed surveys of U.S. soils. ISRIC SoilGrids 250m : which offers global coverage in a grid format. Usage USDA SSURGO The USDA Soil Survey Geographic (SSURGO) database is a comprehensive resource for soil data collected by the Natural Resources Conservation Service (NRCS) across the United States and the Territories. This database provides detailed information on soil properties and classifications. The data is collected through extensive field surveys and laboratory analysis. For more detailed information, visit the USDA NRCS SSURGO page. To fetch and output soil files using the USDA SSURGO database, following commands could be used. For a specific location, specify the latitude and longitude coordinates to generate a soil file named out_name.SOL. # Fetch and output soil files for a specific latitude and longitude >> geo-epic soil usda --fetch {lat} {lon} --out {out_path} # Fetch for a list of locations in a csv file with lat, lon, out_path columns >> geo-epic soil usda --fetch {list.csv} --out {column_name} # Fetch for crop sequence boundaries shape file. >> geo-epic soil usda --fetch {aoi_csb.shp} --out {out_dir} Processing ssurgo gdb file : To process a SSURGO GDB file and generate soil files for all unique soils contained in it, follow these steps. For instance, if you require soil files for Maryland, navigate to the 'State Database - Soils' section, and download the 'gSSURGO_MD.zip' file. Once the download is complete, extract the contents and place the GDB file in the 'soil' folder within your workspace. Use the following command to generate the soil files for all mukeys. Link: https://www.nrcs.usda.gov/resources/data-and-reports/gridded-soil-survey-geographic-gssurgo-database >> geo-epic soil process_gdb -i {path/to/ssurgo.gdb} -o {out_dir} ISRIC Soil Grids Data The ISRIC Soil Grids 250 meters database is an advanced resource providing high-resolution global soil information. Managed by the International Soil Reference and Information Centre (ISRIC) , it uses state-of-the-art machine learning methods to map soil properties across the globe. The prediction models are based on soil profile observations and environmental covariates, including climate, land cover, and terrain morphology. SoilGrids offers soil properties at six standard depth intervals at 250 meters spatial resolution. For more detailed information, visit the ISRIC Soil Grids page. To fetch and output soil files using the ISRIC Soil Grids 250 meters database, you can use the following commands. # Fetch and output soil files for a specific latitude and longitude >> geo-epic soil soilgrids --fetch {lat} {lon} --out {out_path} # Fetch for a list of locations in a csv file with lat, lon, out_path columns >> geo-epic soil soilgrids --fetch {list.csv} --out {column_name} Once the tool finishes running, you should see files named {out_name}.SOL in your specified output directory. Open this file to verify that it contains the necessary soil data formatted correctly for use in the EPIC model. Refer to the EPIC manual for Soil file formatting","title":"Soil Module"},{"location":"Soil/#soil-module","text":"In agriculture simulations, such as those conducted using the EPIC model, soil data directly influences water availability, nutrient supply, and overall crop growth predictions. Soil input files to the model contain detailed information about the soil properties of a specific location, depth wise. Geo-Epic helps in generating soil files required by the EPIC Model from two soil data sources: USDA SSURGO : which contains detailed surveys of U.S. soils. ISRIC SoilGrids 250m : which offers global coverage in a grid format.","title":"Soil Module"},{"location":"Soil/#usage","text":"","title":"Usage"},{"location":"Soil/#usda-ssurgo","text":"The USDA Soil Survey Geographic (SSURGO) database is a comprehensive resource for soil data collected by the Natural Resources Conservation Service (NRCS) across the United States and the Territories. This database provides detailed information on soil properties and classifications. The data is collected through extensive field surveys and laboratory analysis. For more detailed information, visit the USDA NRCS SSURGO page. To fetch and output soil files using the USDA SSURGO database, following commands could be used. For a specific location, specify the latitude and longitude coordinates to generate a soil file named out_name.SOL. # Fetch and output soil files for a specific latitude and longitude >> geo-epic soil usda --fetch {lat} {lon} --out {out_path} # Fetch for a list of locations in a csv file with lat, lon, out_path columns >> geo-epic soil usda --fetch {list.csv} --out {column_name} # Fetch for crop sequence boundaries shape file. >> geo-epic soil usda --fetch {aoi_csb.shp} --out {out_dir} Processing ssurgo gdb file : To process a SSURGO GDB file and generate soil files for all unique soils contained in it, follow these steps. For instance, if you require soil files for Maryland, navigate to the 'State Database - Soils' section, and download the 'gSSURGO_MD.zip' file. Once the download is complete, extract the contents and place the GDB file in the 'soil' folder within your workspace. Use the following command to generate the soil files for all mukeys. Link: https://www.nrcs.usda.gov/resources/data-and-reports/gridded-soil-survey-geographic-gssurgo-database >> geo-epic soil process_gdb -i {path/to/ssurgo.gdb} -o {out_dir}","title":"USDA SSURGO"},{"location":"Soil/#isric-soil-grids-data","text":"The ISRIC Soil Grids 250 meters database is an advanced resource providing high-resolution global soil information. Managed by the International Soil Reference and Information Centre (ISRIC) , it uses state-of-the-art machine learning methods to map soil properties across the globe. The prediction models are based on soil profile observations and environmental covariates, including climate, land cover, and terrain morphology. SoilGrids offers soil properties at six standard depth intervals at 250 meters spatial resolution. For more detailed information, visit the ISRIC Soil Grids page. To fetch and output soil files using the ISRIC Soil Grids 250 meters database, you can use the following commands. # Fetch and output soil files for a specific latitude and longitude >> geo-epic soil soilgrids --fetch {lat} {lon} --out {out_path} # Fetch for a list of locations in a csv file with lat, lon, out_path columns >> geo-epic soil soilgrids --fetch {list.csv} --out {column_name} Once the tool finishes running, you should see files named {out_name}.SOL in your specified output directory. Open this file to verify that it contains the necessary soil data formatted correctly for use in the EPIC model. Refer to the EPIC manual for Soil file formatting","title":"ISRIC Soil Grids Data"},{"location":"Weather/","text":"Weather Module Weather data is vital in providing essential environmental inputs that significantly influence crop growth and development. Reliable weather inputs ensure that agricultural simulations reflect realistic responses to climatic conditions. The EPIC model requires weather input files that detail daily and monthly climatic variables. Daily files provide day-to-day weather data, while monthly files summarize the average or total values per month. These files are crucial for driving the daily simulation processes in EPIC. Fetching Weather Data Geo-Epic streamlines the process of fetching and organizing weather data essential for EPIC simulations. It supports the creation of weather input files from daymet, and also from sophisticated datasets available through Google Earth Engine. One can define a composite collection in the config file, detailing the specific variables to select from each data source, tailoring the dataset to meet the needs of their simulations. Using GEE collections Geo-epic allows the integration of weather and climate data sources on GEE. To explore the datasets, visit Google Earth Engine's dataset catalog and GEE Community Catalog . Private assets can also be uploaded to Earth Engine, to use them in combination with existing datasets. Below is an example of configuration file that can be used to create weather input files. Example config files: using AgERA5 # Global parameters global_scope: time_range: ['2002-01-01', '2022-12-31'] variables: ['srad', 'tmax', 'tmin', 'prcp', 'rh', 'ws'] resolution: 9600 # Specify Earth Engine (EE) collections and their respective variables collections: daymet: collection: 'projects/climate-engine-pro/assets/ce-ag-era5/daily' variables: srad: b('Solar_Radiation_Flux') tmax: b('Temperature_Air_2m_Max_24h') - 273.15 tmin: b('Temperature_Air_2m_Min_24h') - 273.15 prcp: b('Precipitation_Flux') rh: b('Relative_Humidity_2m_06h') ws: b('Wind_Speed_10m_Mean') Using the config file to get data: # Fetch and output weather input files for a specific latitude and longitude >> geo-epic weather config.yml --fetch {lat} {lon} --out {out_path} # Fetch for a list of locations in a csv file with lat, lon, out_path columns >> geo-epic weather config.yml --fetch {list.csv} --out {column_name} # Fetch for crop sequence boundaries shape file. >> geo-epic weather config.yml --fetch {aoi_csb.shp} --out {out_dir} From Daymet and NLDAS To fetch weather data for a specific latitude and longitude using the Daymet dataset, start by downloading the windspeed data from the NLDAS dataset and saving it to the specified directory. Afterward, fetch the other required weather data from the Daymet dataset. # To download windspeed data, use the following command >> geo-epic weather windspeed -bbox <bounding_box> -start <start_date> -end <end_date> -out_dir './weather' # To fetch and output weather input files for a specific latitude and longitude >> geo-epic weather daymet --fetch {lat} {lon} -start <start_date> -end <end_date> --out './weather'","title":"Weather Module"},{"location":"Weather/#weather-module","text":"Weather data is vital in providing essential environmental inputs that significantly influence crop growth and development. Reliable weather inputs ensure that agricultural simulations reflect realistic responses to climatic conditions. The EPIC model requires weather input files that detail daily and monthly climatic variables. Daily files provide day-to-day weather data, while monthly files summarize the average or total values per month. These files are crucial for driving the daily simulation processes in EPIC.","title":"Weather Module"},{"location":"Weather/#fetching-weather-data","text":"Geo-Epic streamlines the process of fetching and organizing weather data essential for EPIC simulations. It supports the creation of weather input files from daymet, and also from sophisticated datasets available through Google Earth Engine. One can define a composite collection in the config file, detailing the specific variables to select from each data source, tailoring the dataset to meet the needs of their simulations.","title":"Fetching Weather Data"},{"location":"Weather/#using-gee-collections","text":"Geo-epic allows the integration of weather and climate data sources on GEE. To explore the datasets, visit Google Earth Engine's dataset catalog and GEE Community Catalog . Private assets can also be uploaded to Earth Engine, to use them in combination with existing datasets. Below is an example of configuration file that can be used to create weather input files. Example config files: using AgERA5 # Global parameters global_scope: time_range: ['2002-01-01', '2022-12-31'] variables: ['srad', 'tmax', 'tmin', 'prcp', 'rh', 'ws'] resolution: 9600 # Specify Earth Engine (EE) collections and their respective variables collections: daymet: collection: 'projects/climate-engine-pro/assets/ce-ag-era5/daily' variables: srad: b('Solar_Radiation_Flux') tmax: b('Temperature_Air_2m_Max_24h') - 273.15 tmin: b('Temperature_Air_2m_Min_24h') - 273.15 prcp: b('Precipitation_Flux') rh: b('Relative_Humidity_2m_06h') ws: b('Wind_Speed_10m_Mean') Using the config file to get data: # Fetch and output weather input files for a specific latitude and longitude >> geo-epic weather config.yml --fetch {lat} {lon} --out {out_path} # Fetch for a list of locations in a csv file with lat, lon, out_path columns >> geo-epic weather config.yml --fetch {list.csv} --out {column_name} # Fetch for crop sequence boundaries shape file. >> geo-epic weather config.yml --fetch {aoi_csb.shp} --out {out_dir}","title":"Using GEE collections"},{"location":"Weather/#from-daymet-and-nldas","text":"To fetch weather data for a specific latitude and longitude using the Daymet dataset, start by downloading the windspeed data from the NLDAS dataset and saving it to the specified directory. Afterward, fetch the other required weather data from the Daymet dataset. # To download windspeed data, use the following command >> geo-epic weather windspeed -bbox <bounding_box> -start <start_date> -end <end_date> -out_dir './weather' # To fetch and output weather input files for a specific latitude and longitude >> geo-epic weather daymet --fetch {lat} {lon} -start <start_date> -end <end_date> --out './weather'","title":"From Daymet and NLDAS"},{"location":"api/","text":"Commands Available (ToDo) Geo-Epic allows you to run various commands. The structure is as show below: geo-epic {module} {func} -options example usage: geo-epic workspace new -w Test List of Modules and Functions: workspace new : Create a new workspace with a template structure. prepare : Prepare the input files using config file. run : Execute the simulations. post_process : Process Output files from simulation runs. weather ee : windspeed : download_daily : Download daily weather data. daily2monthly : Convert daily weather data to monthly. soil usda : isirc : process_gdb : Process ssurgo gdb file. sites process_foi : Process fields of interest file. (TODO) generate : Generate site files from processed data. For more details on each command and its options, use: geo-epic {module} {func} --help","title":"API"},{"location":"api/#commands-available","text":"","title":"Commands Available"},{"location":"api/#todo","text":"Geo-Epic allows you to run various commands. The structure is as show below: geo-epic {module} {func} -options example usage: geo-epic workspace new -w Test","title":"(ToDo)"},{"location":"api/#list-of-modules-and-functions","text":"","title":"List of Modules and Functions:"},{"location":"api/#workspace","text":"new : Create a new workspace with a template structure. prepare : Prepare the input files using config file. run : Execute the simulations. post_process : Process Output files from simulation runs.","title":"workspace"},{"location":"api/#weather","text":"ee : windspeed : download_daily : Download daily weather data. daily2monthly : Convert daily weather data to monthly.","title":"weather"},{"location":"api/#soil","text":"usda : isirc : process_gdb : Process ssurgo gdb file.","title":"soil"},{"location":"api/#sites","text":"process_foi : Process fields of interest file. (TODO) generate : Generate site files from processed data. For more details on each command and its options, use: geo-epic {module} {func} --help","title":"sites"},{"location":"csb/","text":"Crop Sequence Boundaries For effective simulations using the EPIC model, it is essential to have land units that are characterized by uniform soil properties and consistent management practices. One way to achieve this for the USA is by utilizing the Crop Sequence Boundaries (CSB) dataset. The CSB dataset is derived by analyzing annual variations in the USDA's Cropland Data Layer (CDL). The CSB method involves identifying and demarcating the boundaries of agricultural fields that have maintained consistent crop rotation sequence over several years. Crop Sequence Boundaries (CSB): Delineated Fields Using Remotely Sensed Crop Rotations . USDA-NASS & Global Conservation Institute. Hunt, K. A., Abernethy, J., Beeson, P., Bowman, M., Wallander, S., & Williams, R. Obtaining the CSB dataset Visit the following URL: https://www.nass.usda.gov/Research_and_Science/Crop-Sequence-Boundaries/index.php to download the 'Crop Sequence Boundaries 2016-2023' dataset. After downloading, extract the dataset, which includes crop-field shapes for the entire USA. You can then use crop_csb tool to clip it to fit your Area of Interest (AOI). If your study focuses on Maryland, clip the shapefile for Maryland and save it. Clipping the CSB file to your Area of Interest Geo-Epic comes with a command-line tool to filter and clip the CSB file for your specific region of interest. The tool can be invoked with various options to specify the region: # Help with the options provided by the tool >> geo-epic crop_csb -h # Cropping the csb to get the shapefile for Maryland: >> geo-epic crop_csb path/to/input.gdb output.shp --state_name \"Maryland\" # Using the state FIPS code (24) for Maryland: >> geo-epic crop_csb path/to/input.gdb output.shp --state_fips \"24\" # To get the shapefile for Montgomery County, Maryland: >> geo-epic crop_csb path/to/input.gdb output.shp --county_name \"Montgomery, Maryland\" # Cropping the CSB using a bounding box: >> geo-epic crop_csb path/to/input.gdb output.shp --bbox \"-77.5,38.0,-76.0,39.5\" # Cropping the csb around a center point with a specified extent in km: >> geo-epic crop_csb path/to/input.gdb output.shp --center \"39.0,-77.0\" --extent \"50x50\" Note: For countries other than USA , a geo-tiff file covering the region of interest with one channel being the cultivated crop land mask of that region and another channel containing corresponding management info ID can be used to utilize Geo-Epic.","title":"Crop Sequence Boundaries"},{"location":"csb/#crop-sequence-boundaries","text":"For effective simulations using the EPIC model, it is essential to have land units that are characterized by uniform soil properties and consistent management practices. One way to achieve this for the USA is by utilizing the Crop Sequence Boundaries (CSB) dataset. The CSB dataset is derived by analyzing annual variations in the USDA's Cropland Data Layer (CDL). The CSB method involves identifying and demarcating the boundaries of agricultural fields that have maintained consistent crop rotation sequence over several years. Crop Sequence Boundaries (CSB): Delineated Fields Using Remotely Sensed Crop Rotations . USDA-NASS & Global Conservation Institute. Hunt, K. A., Abernethy, J., Beeson, P., Bowman, M., Wallander, S., & Williams, R.","title":"Crop Sequence Boundaries"},{"location":"csb/#obtaining-the-csb-dataset","text":"Visit the following URL: https://www.nass.usda.gov/Research_and_Science/Crop-Sequence-Boundaries/index.php to download the 'Crop Sequence Boundaries 2016-2023' dataset. After downloading, extract the dataset, which includes crop-field shapes for the entire USA. You can then use crop_csb tool to clip it to fit your Area of Interest (AOI). If your study focuses on Maryland, clip the shapefile for Maryland and save it.","title":"Obtaining the CSB dataset"},{"location":"csb/#clipping-the-csb-file-to-your-area-of-interest","text":"Geo-Epic comes with a command-line tool to filter and clip the CSB file for your specific region of interest. The tool can be invoked with various options to specify the region: # Help with the options provided by the tool >> geo-epic crop_csb -h # Cropping the csb to get the shapefile for Maryland: >> geo-epic crop_csb path/to/input.gdb output.shp --state_name \"Maryland\" # Using the state FIPS code (24) for Maryland: >> geo-epic crop_csb path/to/input.gdb output.shp --state_fips \"24\" # To get the shapefile for Montgomery County, Maryland: >> geo-epic crop_csb path/to/input.gdb output.shp --county_name \"Montgomery, Maryland\" # Cropping the CSB using a bounding box: >> geo-epic crop_csb path/to/input.gdb output.shp --bbox \"-77.5,38.0,-76.0,39.5\" # Cropping the csb around a center point with a specified extent in km: >> geo-epic crop_csb path/to/input.gdb output.shp --center \"39.0,-77.0\" --extent \"50x50\" Note: For countries other than USA , a geo-tiff file covering the region of interest with one channel being the cultivated crop land mask of that region and another channel containing corresponding management info ID can be used to utilize Geo-Epic.","title":"Clipping the CSB file to your Area of Interest"},{"location":"epic/","text":"Environmental Policy Integrated Climate Model The Environmental Policy Integrated Climate (EPIC) model, originally known as the Erosion/Productivity Impact Calculator, is designed to simulate a field, farm or small watershed , that is homogenous in terms of climate, soil, land use, and topography. EPIC is capable of simulating around eighty crops . This model helps in analyzing the effects of management strategies on soil erosion and extends to other aspects of agricultural sustainability like water quality, crop yields, plant competition, and pest control. For more details on EPIC model, visit Texas A&M AgriLife site . Initially developed in the early 1980s, (J. R. Williams, Jones, & Dyke, 1984) . EPIC integrated components from previous models such as CREAMS (Knisel, 1980) and SWRRB (J. R. Williams, Nicks, & Arnold, 1985) . The model was later enhanced with a pesticide component from GLEAMS (Leonard, 1987) to assess pesticide fate, further developed by Sabbagh, Geleta, Elliott, Williams, & Griggs (1991) . EPIC has evolved to address broader issues such as global climate change impacts, biomass production for energy, and landfill design, making it a versatile tool in environmental and agricultural management. Refer to the user manual for detailed guidance on using EPIC: Alternative text for the PDF","title":"EPIC Model"},{"location":"epic/#environmental-policy-integrated-climate-model","text":"The Environmental Policy Integrated Climate (EPIC) model, originally known as the Erosion/Productivity Impact Calculator, is designed to simulate a field, farm or small watershed , that is homogenous in terms of climate, soil, land use, and topography. EPIC is capable of simulating around eighty crops . This model helps in analyzing the effects of management strategies on soil erosion and extends to other aspects of agricultural sustainability like water quality, crop yields, plant competition, and pest control. For more details on EPIC model, visit Texas A&M AgriLife site . Initially developed in the early 1980s, (J. R. Williams, Jones, & Dyke, 1984) . EPIC integrated components from previous models such as CREAMS (Knisel, 1980) and SWRRB (J. R. Williams, Nicks, & Arnold, 1985) . The model was later enhanced with a pesticide component from GLEAMS (Leonard, 1987) to assess pesticide fate, further developed by Sabbagh, Geleta, Elliott, Williams, & Griggs (1991) . EPIC has evolved to address broader issues such as global climate change impacts, biomass production for energy, and landfill design, making it a versatile tool in environmental and agricultural management. Refer to the user manual for detailed guidance on using EPIC: Alternative text for the PDF","title":"Environmental Policy Integrated Climate Model"},{"location":"opt/","text":"Overview The Calibration Module in Geo-Epic is developed to assist in tuning desired parameters involved in the EPIC model based on observational data, such as Leaf Area Index (LAI), Net Ecosystem Exchange (NEE), crop yield, or biomass. This allows model parameters to be refined to better reflect specific local conditions or experimental results. Getting Started To begin calibration, import the calibration module from the package: <ToDo>","title":"Model Calibration"},{"location":"opt/#overview","text":"The Calibration Module in Geo-Epic is developed to assist in tuning desired parameters involved in the EPIC model based on observational data, such as Leaf Area Index (LAI), Net Ecosystem Exchange (NEE), crop yield, or biomass. This allows model parameters to be refined to better reflect specific local conditions or experimental results.","title":"Overview"},{"location":"opt/#getting-started","text":"To begin calibration, import the calibration module from the package:","title":"Getting Started"},{"location":"opt/#todo","text":"","title":"&lt;ToDo\u000262\u0003"},{"location":"runexp/","text":"Running the model <ToDo> from geoEpic import Site, EpicModel # initialise a site object site = Site(opc = './continuous_corn.OPC', # management file dly = './1123455.DLY', # daily weather file sol = './Andisol.SOL', # soil file sit = './1.SIT') # site file # initialise the EPIC model model = EpicModel(path = './model/EPIC2301dt20230820') model.setup(start_year = 2014, duration = 10) model.set_output_types(['ACY', 'DGN']) # run the simulation for the site model.run(site) # get the required outputs acy = model.outputs['ACY'] model.close() Loading from config files: site = Site.from_config(lat = , lon = , config = './config.yml') model = EpicModel.from_config(config = './config.yml') model.run(site) model.close() Example config file: # Model details EPICModel: ./model/EPIC2301dt20230820 start_year: 1995 duration: 25 output_types: - ACY # Annual Crop data file - DGN # Daily general output file log_dir: ./log output_dir: ./output To edit the OPC, SOL or files in the epic model folder, you could use the epic_editor. the following command will copy the epiceditor in to your current folder. >> geo-epic workspace add epic_editor Running an EPIC Experiment 1. Create new workspace epic_pkg workspace new -w Test cd Test It willl create a new workspace in the new directory named 'Test'. This 'Test' folder will automatically create sub-folders for EPIC model like model, opc, sites, soil, weather and a config.yml doc in it. You need to to go to Test folder before simulation starts. 2. Edit config file as needed This package is mainly designed for study regions in the USA. In the config.yml file, update the settings in the config file based on your area of interest (AOI) and preferences. For example, if you need to run the model for the state of Maryland, USA, modify these rows as follows: EXPName: Nitrogen Assessment (Your Experiment Name) Region: Maryland code: MD Fields_of_Interests: ./CropRotations/MDRotFilt.shp Note: The MDRotFilt.shp file is the same one downloaded and placed in the CropRotations folder in the previous step. soil: ssurgo_gdb: ./soil/gSSURGO_MD.gdb Guideline: The rule of thumb is to edit the configuration file using the region code specific to your study region, as done here using \"MD\" throughout the config file. 3. Prepare OPC File OPC refers to the agricultural management practice files which is yet to automated. For now, you need to prpare management files and keep it in a new folder named 'OPC' inside the 'Test' directory. 4. Prepare the workspace epic_pkg workspace prepare This command will automatically pre-process the input files before simulation. 5. And execute the simulations epic_pkg workspace run This command will simulate the operation/s and automatically save the results in a new folder named 'Output'. This command will also create a post_process.pynb doc which will have an example code to visualize the required parameters from ACY and DGN files. You can edit this code as per your requirements. You just have to identify the parameters and edit accordingly. Example Visualization 6. Post-process the output visualization You need to post-process the output files according to your interests. Generally, as an agricultural reserachers you need to process the DGN and ACY files. For post-processing epic_pkg workspace post_process This will run the example code post_process.pynb which has been created in the Test folder. It will take a variable called 'YLDG' which denotes the yearly yield in t/ha/yr for all the sites and put it in a sepearte column corresponding to all the site ids with creatinh a yldg.csv file. For visualization epic_pkg workspace visualize It will simply plot the 'YLDG' variable corresponding to the site ids and crate a map for study region. Your plot will look like this:","title":"Running an Experiment"},{"location":"runexp/#running-the-model","text":"","title":"Running the model"},{"location":"runexp/#todo","text":"from geoEpic import Site, EpicModel # initialise a site object site = Site(opc = './continuous_corn.OPC', # management file dly = './1123455.DLY', # daily weather file sol = './Andisol.SOL', # soil file sit = './1.SIT') # site file # initialise the EPIC model model = EpicModel(path = './model/EPIC2301dt20230820') model.setup(start_year = 2014, duration = 10) model.set_output_types(['ACY', 'DGN']) # run the simulation for the site model.run(site) # get the required outputs acy = model.outputs['ACY'] model.close() Loading from config files: site = Site.from_config(lat = , lon = , config = './config.yml') model = EpicModel.from_config(config = './config.yml') model.run(site) model.close() Example config file: # Model details EPICModel: ./model/EPIC2301dt20230820 start_year: 1995 duration: 25 output_types: - ACY # Annual Crop data file - DGN # Daily general output file log_dir: ./log output_dir: ./output To edit the OPC, SOL or files in the epic model folder, you could use the epic_editor. the following command will copy the epiceditor in to your current folder. >> geo-epic workspace add epic_editor","title":"&lt;ToDo\u000262\u0003"},{"location":"runexp/#running-an-epic-experiment","text":"","title":"Running an EPIC Experiment"},{"location":"runexp/#1-create-new-workspace","text":"epic_pkg workspace new -w Test cd Test It willl create a new workspace in the new directory named 'Test'. This 'Test' folder will automatically create sub-folders for EPIC model like model, opc, sites, soil, weather and a config.yml doc in it. You need to to go to Test folder before simulation starts.","title":"1. Create new workspace"},{"location":"runexp/#2-edit-config-file-as-needed","text":"This package is mainly designed for study regions in the USA. In the config.yml file, update the settings in the config file based on your area of interest (AOI) and preferences. For example, if you need to run the model for the state of Maryland, USA, modify these rows as follows: EXPName: Nitrogen Assessment (Your Experiment Name) Region: Maryland code: MD Fields_of_Interests: ./CropRotations/MDRotFilt.shp Note: The MDRotFilt.shp file is the same one downloaded and placed in the CropRotations folder in the previous step. soil: ssurgo_gdb: ./soil/gSSURGO_MD.gdb Guideline: The rule of thumb is to edit the configuration file using the region code specific to your study region, as done here using \"MD\" throughout the config file.","title":"2. Edit config file as needed"},{"location":"runexp/#3-prepare-opc-file","text":"OPC refers to the agricultural management practice files which is yet to automated. For now, you need to prpare management files and keep it in a new folder named 'OPC' inside the 'Test' directory.","title":"3. Prepare OPC File"},{"location":"runexp/#4-prepare-the-workspace","text":"epic_pkg workspace prepare This command will automatically pre-process the input files before simulation.","title":"4. Prepare the workspace"},{"location":"runexp/#5-and-execute-the-simulations","text":"epic_pkg workspace run This command will simulate the operation/s and automatically save the results in a new folder named 'Output'. This command will also create a post_process.pynb doc which will have an example code to visualize the required parameters from ACY and DGN files. You can edit this code as per your requirements. You just have to identify the parameters and edit accordingly.","title":"5. And execute the simulations"},{"location":"runexp/#example-visualization","text":"","title":"Example Visualization"},{"location":"runexp/#6-post-process-the-output-visualization","text":"You need to post-process the output files according to your interests. Generally, as an agricultural reserachers you need to process the DGN and ACY files.","title":"6. Post-process the output visualization"},{"location":"runexp/#for-post-processing","text":"epic_pkg workspace post_process This will run the example code post_process.pynb which has been created in the Test folder. It will take a variable called 'YLDG' which denotes the yearly yield in t/ha/yr for all the sites and put it in a sepearte column corresponding to all the site ids with creatinh a yldg.csv file.","title":"For post-processing"},{"location":"runexp/#for-visualization","text":"epic_pkg workspace visualize It will simply plot the 'YLDG' variable corresponding to the site ids and crate a map for study region.","title":"For visualization"},{"location":"runexp/#your-plot-will-look-like-this","text":"","title":"Your plot will look like this:"}]}